<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>基模 on Example Site</title>
        <link>https://caxlee.github.io/tags/%E5%9F%BA%E6%A8%A1/</link>
        <description>Recent content in 基模 on Example Site</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <copyright>Example Person</copyright>
        <lastBuildDate>Tue, 15 Jul 2025 02:40:55 +0800</lastBuildDate><atom:link href="https://caxlee.github.io/tags/%E5%9F%BA%E6%A8%A1/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>「流匹配」成ICML 2025超热门主题！网友：都说了学物理的不准转计算机</title>
        <link>https://caxlee.github.io/p/%E6%B5%81%E5%8C%B9%E9%85%8D%E6%88%90icml-2025%E8%B6%85%E7%83%AD%E9%97%A8%E4%B8%BB%E9%A2%98%E7%BD%91%E5%8F%8B%E9%83%BD%E8%AF%B4%E4%BA%86%E5%AD%A6%E7%89%A9%E7%90%86%E7%9A%84%E4%B8%8D%E5%87%86%E8%BD%AC%E8%AE%A1%E7%AE%97%E6%9C%BA/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E6%B5%81%E5%8C%B9%E9%85%8D%E6%88%90icml-2025%E8%B6%85%E7%83%AD%E9%97%A8%E4%B8%BB%E9%A2%98%E7%BD%91%E5%8F%8B%E9%83%BD%E8%AF%B4%E4%BA%86%E5%AD%A6%E7%89%A9%E7%90%86%E7%9A%84%E4%B8%8D%E5%87%86%E8%BD%AC%E8%AE%A1%E7%AE%97%E6%9C%BA/</guid>
        <description>&lt;p&gt;流匹配技术在生成式 AI 领域备受关注，结合流体力学原理，实现噪声到数据的转化。ICML 2025将探讨其高效、简洁的模型形态。&lt;/p&gt;</description>
        </item>
        <item>
        <title>ACL 2025｜自我怀疑还是自我纠正？清华团队揭示LLMs反思技术的暗面</title>
        <link>https://caxlee.github.io/p/acl-2025%E8%87%AA%E6%88%91%E6%80%80%E7%96%91%E8%BF%98%E6%98%AF%E8%87%AA%E6%88%91%E7%BA%A0%E6%AD%A3%E6%B8%85%E5%8D%8E%E5%9B%A2%E9%98%9F%E6%8F%AD%E7%A4%BAllms%E5%8F%8D%E6%80%9D%E6%8A%80%E6%9C%AF%E7%9A%84%E6%9A%97%E9%9D%A2/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/acl-2025%E8%87%AA%E6%88%91%E6%80%80%E7%96%91%E8%BF%98%E6%98%AF%E8%87%AA%E6%88%91%E7%BA%A0%E6%AD%A3%E6%B8%85%E5%8D%8E%E5%9B%A2%E9%98%9F%E6%8F%AD%E7%A4%BAllms%E5%8F%8D%E6%80%9D%E6%8A%80%E6%9C%AF%E7%9A%84%E6%9A%97%E9%9D%A2/</guid>
        <description>&lt;p&gt;研究揭示反思技术在LLMs中的失败原因：内部答案波动、提示语偏差、认知偏差。提出问题重复和少样本微调缓解策略。&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI下半场的「Game Changer」，直让老外惊呼「Amazing」</title>
        <link>https://caxlee.github.io/p/ai%E4%B8%8B%E5%8D%8A%E5%9C%BA%E7%9A%84game-changer%E7%9B%B4%E8%AE%A9%E8%80%81%E5%A4%96%E6%83%8A%E5%91%BCamazing/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/ai%E4%B8%8B%E5%8D%8A%E5%9C%BA%E7%9A%84game-changer%E7%9B%B4%E8%AE%A9%E8%80%81%E5%A4%96%E6%83%8A%E5%91%BCamazing/</guid>
        <description>&lt;p&gt;中国电信推出的智传网（AI Flow）技术，通过端-边-云协同、家族式同源模型和智能涌现，实现普适智能应用，解决AI下半场挑战。&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI编程「反直觉」调研引300万围观！开发者坚信提速20%，实测反慢19%</title>
        <link>https://caxlee.github.io/p/ai%E7%BC%96%E7%A8%8B%E5%8F%8D%E7%9B%B4%E8%A7%89%E8%B0%83%E7%A0%94%E5%BC%95300%E4%B8%87%E5%9B%B4%E8%A7%82%E5%BC%80%E5%8F%91%E8%80%85%E5%9D%9A%E4%BF%A1%E6%8F%90%E9%80%9F20%E5%AE%9E%E6%B5%8B%E5%8F%8D%E6%85%A219/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/ai%E7%BC%96%E7%A8%8B%E5%8F%8D%E7%9B%B4%E8%A7%89%E8%B0%83%E7%A0%94%E5%BC%95300%E4%B8%87%E5%9B%B4%E8%A7%82%E5%BC%80%E5%8F%91%E8%80%85%E5%9D%9A%E4%BF%A1%E6%8F%90%E9%80%9F20%E5%AE%9E%E6%B5%8B%E5%8F%8D%E6%85%A219/</guid>
        <description>&lt;p&gt;AI编程工具预期提速20%，实测反慢19%。METR调研显示，AI对开发者生产力影响不如预期。&lt;/p&gt;</description>
        </item>
        <item>
        <title>EasyCache：无需训练的视频扩散模型推理加速——极简高效的视频生成提速方案</title>
        <link>https://caxlee.github.io/p/easycache%E6%97%A0%E9%9C%80%E8%AE%AD%E7%BB%83%E7%9A%84%E8%A7%86%E9%A2%91%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E6%9E%81%E7%AE%80%E9%AB%98%E6%95%88%E7%9A%84%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E6%8F%90%E9%80%9F%E6%96%B9%E6%A1%88/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/easycache%E6%97%A0%E9%9C%80%E8%AE%AD%E7%BB%83%E7%9A%84%E8%A7%86%E9%A2%91%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E6%9E%81%E7%AE%80%E9%AB%98%E6%95%88%E7%9A%84%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E6%8F%90%E9%80%9F%E6%96%B9%E6%A1%88/</guid>
        <description>&lt;p&gt;EasyCache是无需训练的视频扩散模型推理加速方案，通过动态检测稳定期减少冗余推理步骤。实验结果显示在多个视频生成模型上取得显著加速且质量几乎无损。&lt;/p&gt;</description>
        </item>
        <item>
        <title>How an MIT professor introduced hundreds of thousands of students to neuroscience</title>
        <link>https://caxlee.github.io/p/how-an-mit-professor-introduced-hundreds-of-thousands-of-students/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/how-an-mit-professor-introduced-hundreds-of-thousands-of-students/</guid>
        <description>&lt;p&gt;MIT教授Mark Bear的《神经科学：探索大脑》是领先的入门神经科学教材，通过引人入胜的方式向数十万学生介绍神经科学领域。书籍注重科学严谨性，同时以精美插图和发现历程为特色，传达对大脑的热爱和兴奋。&lt;/p&gt;</description>
        </item>
        <item>
        <title>ICCV 2025 | 清华&amp;腾讯混元X发现「视觉头」机制：仅5%注意力头负责多模态视觉理解</title>
        <link>https://caxlee.github.io/p/iccv-2025-%E6%B8%85%E5%8D%8E%E8%85%BE%E8%AE%AF%E6%B7%B7%E5%85%83x%E5%8F%91%E7%8E%B0%E8%A7%86%E8%A7%89%E5%A4%B4%E6%9C%BA%E5%88%B6%E4%BB%855%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%A4%B4%E8%B4%9F%E8%B4%A3%E5%A4%9A%E6%A8%A1%E6%80%81%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/iccv-2025-%E6%B8%85%E5%8D%8E%E8%85%BE%E8%AE%AF%E6%B7%B7%E5%85%83x%E5%8F%91%E7%8E%B0%E8%A7%86%E8%A7%89%E5%A4%B4%E6%9C%BA%E5%88%B6%E4%BB%855%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%A4%B4%E8%B4%9F%E8%B4%A3%E5%A4%9A%E6%A8%A1%E6%80%81%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3/</guid>
        <description>&lt;p&gt;发现多模态大模型中仅5%的视觉头负责视觉理解，提出SparseMM优化KV-Cache资源分配，取得性能与效率平衡&lt;/p&gt;</description>
        </item>
        <item>
        <title>ICCV2025 | 多视图生成新范式-利用自回归模型探索多视图生成</title>
        <link>https://caxlee.github.io/p/iccv2025-%E5%A4%9A%E8%A7%86%E5%9B%BE%E7%94%9F%E6%88%90%E6%96%B0%E8%8C%83%E5%BC%8F-%E5%88%A9%E7%94%A8%E8%87%AA%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E6%8E%A2%E7%B4%A2%E5%A4%9A%E8%A7%86%E5%9B%BE%E7%94%9F%E6%88%90/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/iccv2025-%E5%A4%9A%E8%A7%86%E5%9B%BE%E7%94%9F%E6%88%90%E6%96%B0%E8%8C%83%E5%BC%8F-%E5%88%A9%E7%94%A8%E8%87%AA%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E6%8E%A2%E7%B4%A2%E5%A4%9A%E8%A7%86%E5%9B%BE%E7%94%9F%E6%88%90/</guid>
        <description>&lt;p&gt;MVAR是一种自回归生成多视图图像的方法，提高多视图一致性。解决了Diffusion模型的局限性，包括多模态条件控制和数据稀缺。采用多模态条件嵌入网络和ShufV数据增强策略优化生成质量。&lt;/p&gt;</description>
        </item>
        <item>
        <title>ICML 2025 Oral！北大和腾讯优图破解AI生成图像检测泛化难题：正交子空间分解</title>
        <link>https://caxlee.github.io/p/icml-2025-oral%E5%8C%97%E5%A4%A7%E5%92%8C%E8%85%BE%E8%AE%AF%E4%BC%98%E5%9B%BE%E7%A0%B4%E8%A7%A3ai%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E6%A3%80%E6%B5%8B%E6%B3%9B%E5%8C%96%E9%9A%BE%E9%A2%98%E6%AD%A3%E4%BA%A4%E5%AD%90%E7%A9%BA%E9%97%B4%E5%88%86%E8%A7%A3/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/icml-2025-oral%E5%8C%97%E5%A4%A7%E5%92%8C%E8%85%BE%E8%AE%AF%E4%BC%98%E5%9B%BE%E7%A0%B4%E8%A7%A3ai%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E6%A3%80%E6%B5%8B%E6%B3%9B%E5%8C%96%E9%9A%BE%E9%A2%98%E6%AD%A3%E4%BA%A4%E5%AD%90%E7%A9%BA%E9%97%B4%E5%88%86%E8%A7%A3/</guid>
        <description>&lt;p&gt;北大和腾讯优图破解AI生成图像检测泛化难题，提出正交子空间分解方法，显著提升泛化能力。&lt;/p&gt;</description>
        </item>
        <item>
        <title>OpenAI的o3在新的「解答科学问题AI排行榜」上排名第一，DeepSeek的R1排名第二</title>
        <link>https://caxlee.github.io/p/openai%E7%9A%84o3%E5%9C%A8%E6%96%B0%E7%9A%84%E8%A7%A3%E7%AD%94%E7%A7%91%E5%AD%A6%E9%97%AE%E9%A2%98ai%E6%8E%92%E8%A1%8C%E6%A6%9C%E4%B8%8A%E6%8E%92%E5%90%8D%E7%AC%AC%E4%B8%80deepseek%E7%9A%84r1%E6%8E%92%E5%90%8D%E7%AC%AC%E4%BA%8C/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/openai%E7%9A%84o3%E5%9C%A8%E6%96%B0%E7%9A%84%E8%A7%A3%E7%AD%94%E7%A7%91%E5%AD%A6%E9%97%AE%E9%A2%98ai%E6%8E%92%E8%A1%8C%E6%A6%9C%E4%B8%8A%E6%8E%92%E5%90%8D%E7%AC%AC%E4%B8%80deepseek%E7%9A%84r1%E6%8E%92%E5%90%8D%E7%AC%AC%E4%BA%8C/</guid>
        <description>&lt;p&gt;OpenAI的o3在解答科学问题AI排行榜上位居第一，DeepSeek的R1排名第二。SciArena评选23个大型语言模型在科学问题上的表现，o3脱颖而出。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Scientists discover compounds that help cells fight a wide range of viruses</title>
        <link>https://caxlee.github.io/p/scientists-discover-compounds-that-help-cells-fight-a-wide-range/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/scientists-discover-compounds-that-help-cells-fight-a-wide-range/</guid>
        <description>&lt;p&gt;科学家发现化合物可激活宿主细胞内的防御途径，对抗多种病毒感染，包括RSV、单纯疱疹病毒和寨卡病毒。这些化合物有望成为广谱抗病毒药物，可对抗各类病毒，激活细胞防御系统，提高对病毒感染的抵抗力。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Study shows a link between obesity and what’s on local restaurant menus</title>
        <link>https://caxlee.github.io/p/study-shows-a-link-between-obesity-and-whats-on-local-restaurant/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/study-shows-a-link-between-obesity-and-whats-on-local-restaurant/</guid>
        <description>&lt;p&gt;研究发现，当地餐厅菜单与肥胖之间存在关联。研究使用新方法分析全球三大城市，发现附近饮食选择少且营养不良与肥胖等健康问题相关。研究突破以往对食品荒漠的研究，更全面评估人们消费的食物。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Windsurf交易内幕疯传：24亿美元被瓜分，背刺数百员工？</title>
        <link>https://caxlee.github.io/p/windsurf%E4%BA%A4%E6%98%93%E5%86%85%E5%B9%95%E7%96%AF%E4%BC%A024%E4%BA%BF%E7%BE%8E%E5%85%83%E8%A2%AB%E7%93%9C%E5%88%86%E8%83%8C%E5%88%BA%E6%95%B0%E7%99%BE%E5%91%98%E5%B7%A5/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/windsurf%E4%BA%A4%E6%98%93%E5%86%85%E5%B9%95%E7%96%AF%E4%BC%A024%E4%BA%BF%E7%BE%8E%E5%85%83%E8%A2%AB%E7%93%9C%E5%88%86%E8%83%8C%E5%88%BA%E6%95%B0%E7%99%BE%E5%91%98%E5%B7%A5/</guid>
        <description>&lt;p&gt;Windsurf交易内幕：24亿美元被瓜分，背刺员工。谷歌截胡收购，创始人和工程师获利，员工陷困境。&lt;/p&gt;</description>
        </item>
        <item>
        <title>刚刚，OpenAI想收购的Windsurf，被谷歌DeepMind抢走了核心团队</title>
        <link>https://caxlee.github.io/p/%E5%88%9A%E5%88%9Aopenai%E6%83%B3%E6%94%B6%E8%B4%AD%E7%9A%84windsurf%E8%A2%AB%E8%B0%B7%E6%AD%8Cdeepmind%E6%8A%A2%E8%B5%B0%E4%BA%86%E6%A0%B8%E5%BF%83%E5%9B%A2%E9%98%9F/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E5%88%9A%E5%88%9Aopenai%E6%83%B3%E6%94%B6%E8%B4%AD%E7%9A%84windsurf%E8%A2%AB%E8%B0%B7%E6%AD%8Cdeepmind%E6%8A%A2%E8%B5%B0%E4%BA%86%E6%A0%B8%E5%BF%83%E5%9B%A2%E9%98%9F/</guid>
        <description>&lt;p&gt;谷歌DeepMind截胡OpenAI收购的Windsurf，核心团队加入Gemini项目。交易排他性期限到期，Windsurf选择谷歌。Windsurf员工分歧，高管跑路，新任领导层上任。&lt;/p&gt;</description>
        </item>
        <item>
        <title>夜场预告 | WAIC UP!之夜：不是大会延长时，而是另一种打开AI的方式</title>
        <link>https://caxlee.github.io/p/%E5%A4%9C%E5%9C%BA%E9%A2%84%E5%91%8A-waic-up%E4%B9%8B%E5%A4%9C%E4%B8%8D%E6%98%AF%E5%A4%A7%E4%BC%9A%E5%BB%B6%E9%95%BF%E6%97%B6%E8%80%8C%E6%98%AF%E5%8F%A6%E4%B8%80%E7%A7%8D%E6%89%93%E5%BC%80ai%E7%9A%84%E6%96%B9%E5%BC%8F/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E5%A4%9C%E5%9C%BA%E9%A2%84%E5%91%8A-waic-up%E4%B9%8B%E5%A4%9C%E4%B8%8D%E6%98%AF%E5%A4%A7%E4%BC%9A%E5%BB%B6%E9%95%BF%E6%97%B6%E8%80%8C%E6%98%AF%E5%8F%A6%E4%B8%80%E7%A7%8D%E6%89%93%E5%BC%80ai%E7%9A%84%E6%96%B9%E5%BC%8F/</guid>
        <description>&lt;p&gt;WAIC推出首份刊物《WAIC UP!》，探索AI时代进化之路。&lt;/p&gt;</description>
        </item>
        <item>
        <title>无Tokenizer时代真要来了？Mamba作者再发颠覆性论文，挑战Transformer</title>
        <link>https://caxlee.github.io/p/%E6%97%A0tokenizer%E6%97%B6%E4%BB%A3%E7%9C%9F%E8%A6%81%E6%9D%A5%E4%BA%86mamba%E4%BD%9C%E8%80%85%E5%86%8D%E5%8F%91%E9%A2%A0%E8%A6%86%E6%80%A7%E8%AE%BA%E6%96%87%E6%8C%91%E6%88%98transformer/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E6%97%A0tokenizer%E6%97%B6%E4%BB%A3%E7%9C%9F%E8%A6%81%E6%9D%A5%E4%BA%86mamba%E4%BD%9C%E8%80%85%E5%86%8D%E5%8F%91%E9%A2%A0%E8%A6%86%E6%80%A7%E8%AE%BA%E6%96%87%E6%8C%91%E6%88%98transformer/</guid>
        <description>&lt;p&gt;Mamba作者提出的H-Net挑战Transformer，通过动态分块取代Tokenizer，实现端到端语言建模。研究展示H-Net在多领域表现优异，无需Tokenizer训练，性能超越基于BPE的Transformer模型。&lt;/p&gt;</description>
        </item>
        <item>
        <title>智源RoboBrain 2.0&#43;RoboOS 2.0双发：问鼎评测基准最强具身大脑，刷新跨本体多机协作技术范式</title>
        <link>https://caxlee.github.io/p/%E6%99%BA%E6%BA%90robobrain-20roboos-20%E5%8F%8C%E5%8F%91%E9%97%AE%E9%BC%8E%E8%AF%84%E6%B5%8B%E5%9F%BA%E5%87%86%E6%9C%80%E5%BC%BA%E5%85%B7%E8%BA%AB%E5%A4%A7%E8%84%91%E5%88%B7%E6%96%B0%E8%B7%A8%E6%9C%AC%E4%BD%93%E5%A4%9A%E6%9C%BA%E5%8D%8F%E4%BD%9C%E6%8A%80%E6%9C%AF%E8%8C%83%E5%BC%8F/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E6%99%BA%E6%BA%90robobrain-20roboos-20%E5%8F%8C%E5%8F%91%E9%97%AE%E9%BC%8E%E8%AF%84%E6%B5%8B%E5%9F%BA%E5%87%86%E6%9C%80%E5%BC%BA%E5%85%B7%E8%BA%AB%E5%A4%A7%E8%84%91%E5%88%B7%E6%96%B0%E8%B7%A8%E6%9C%AC%E4%BD%93%E5%A4%9A%E6%9C%BA%E5%8D%8F%E4%BD%9C%E6%8A%80%E6%9C%AF%E8%8C%83%E5%BC%8F/</guid>
        <description>&lt;p&gt;智源发布RoboBrain 2.0和RoboOS 2.0，刷新具身大脑基准，实现跨本体多机协作。RoboBrain 2.0突破空间理解、时间建模、长链推理瓶颈，RoboOS 2.0构建具身智能SaaS开源框架，推动群体智能发展。&lt;/p&gt;</description>
        </item>
        <item>
        <title>智能科学实验室加速未来科学发现，首版仿真智驱实验室LabUtopia发布</title>
        <link>https://caxlee.github.io/p/%E6%99%BA%E8%83%BD%E7%A7%91%E5%AD%A6%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8A%A0%E9%80%9F%E6%9C%AA%E6%9D%A5%E7%A7%91%E5%AD%A6%E5%8F%91%E7%8E%B0%E9%A6%96%E7%89%88%E4%BB%BF%E7%9C%9F%E6%99%BA%E9%A9%B1%E5%AE%9E%E9%AA%8C%E5%AE%A4labutopia%E5%8F%91%E5%B8%83/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E6%99%BA%E8%83%BD%E7%A7%91%E5%AD%A6%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8A%A0%E9%80%9F%E6%9C%AA%E6%9D%A5%E7%A7%91%E5%AD%A6%E5%8F%91%E7%8E%B0%E9%A6%96%E7%89%88%E4%BB%BF%E7%9C%9F%E6%99%BA%E9%A9%B1%E5%AE%9E%E9%AA%8C%E5%AE%A4labutopia%E5%8F%91%E5%B8%83/</guid>
        <description>&lt;p&gt;LabUtopia发布智能科学实验室，融合认知大模型与具身智能，推动科学发现自动化。LabUtopia支持化学反应建模、流体物理模拟，提出五级任务评估体系，引领具身智能科研新时代。&lt;/p&gt;</description>
        </item>
        <item>
        <title>深夜开源首个万亿模型K2，压力给到OpenAI，Kimi时刻要来了？</title>
        <link>https://caxlee.github.io/p/%E6%B7%B1%E5%A4%9C%E5%BC%80%E6%BA%90%E9%A6%96%E4%B8%AA%E4%B8%87%E4%BA%BF%E6%A8%A1%E5%9E%8Bk2%E5%8E%8B%E5%8A%9B%E7%BB%99%E5%88%B0openaikimi%E6%97%B6%E5%88%BB%E8%A6%81%E6%9D%A5%E4%BA%86/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E6%B7%B1%E5%A4%9C%E5%BC%80%E6%BA%90%E9%A6%96%E4%B8%AA%E4%B8%87%E4%BA%BF%E6%A8%A1%E5%9E%8Bk2%E5%8E%8B%E5%8A%9B%E7%BB%99%E5%88%B0openaikimi%E6%97%B6%E5%88%BB%E8%A6%81%E6%9D%A5%E4%BA%86/</guid>
        <description>&lt;p&gt;Kimi K2是首个万亿模型，采用MuonClip优化器和通用强化学习，具备高效工具调用能力。月之暗面挑战传统优化器，填补数据空白，推动强化学习技术扩展。&lt;/p&gt;</description>
        </item>
        <item>
        <title>用动作分块突破RL极限，伯克利引入模仿学习，超越离线/在线SOTA</title>
        <link>https://caxlee.github.io/p/%E7%94%A8%E5%8A%A8%E4%BD%9C%E5%88%86%E5%9D%97%E7%AA%81%E7%A0%B4rl%E6%9E%81%E9%99%90%E4%BC%AF%E5%85%8B%E5%88%A9%E5%BC%95%E5%85%A5%E6%A8%A1%E4%BB%BF%E5%AD%A6%E4%B9%A0%E8%B6%85%E8%B6%8A%E7%A6%BB%E7%BA%BF%E5%9C%A8%E7%BA%BFsota/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E7%94%A8%E5%8A%A8%E4%BD%9C%E5%88%86%E5%9D%97%E7%AA%81%E7%A0%B4rl%E6%9E%81%E9%99%90%E4%BC%AF%E5%85%8B%E5%88%A9%E5%BC%95%E5%85%A5%E6%A8%A1%E4%BB%BF%E5%AD%A6%E4%B9%A0%E8%B6%85%E8%B6%8A%E7%A6%BB%E7%BA%BF%E5%9C%A8%E7%BA%BFsota/</guid>
        <description>&lt;p&gt;伯克利提出Q-chunking方法，将动作分块引入强化学习，解决探索效率和值传播问题。实验证明在稀疏奖励环境中，QC表现优异，特别适用于离线到在线RL场景。&lt;/p&gt;</description>
        </item>
        <item>
        <title>英伟达&amp;MIT等推出Long-RL，长视频训练速度翻倍</title>
        <link>https://caxlee.github.io/p/%E8%8B%B1%E4%BC%9F%E8%BE%BEmit%E7%AD%89%E6%8E%A8%E5%87%BAlong-rl%E9%95%BF%E8%A7%86%E9%A2%91%E8%AE%AD%E7%BB%83%E9%80%9F%E5%BA%A6%E7%BF%BB%E5%80%8D/</link>
        <pubDate>Tue, 15 Jul 2025 02:40:55 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E8%8B%B1%E4%BC%9F%E8%BE%BEmit%E7%AD%89%E6%8E%A8%E5%87%BAlong-rl%E9%95%BF%E8%A7%86%E9%A2%91%E8%AE%AD%E7%BB%83%E9%80%9F%E5%BA%A6%E7%BF%BB%E5%80%8D/</guid>
        <description>&lt;p&gt;英伟达&amp;amp;MIT推出Long-RL，加速长视频训练。MR-SP并行框架提升训练速度2倍。&lt;/p&gt;</description>
        </item>
        <item>
        <title>A new platform for developing advanced metals at scale</title>
        <link>https://caxlee.github.io/p/a-new-platform-for-developing-advanced-metals-at-scale/</link>
        <pubDate>Mon, 14 Jul 2025 21:13:58 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/a-new-platform-for-developing-advanced-metals-at-scale/</guid>
        <description>&lt;p&gt;Foundation Alloy是由麻省理工学院团队创立的公司，他们利用一种新型生产工艺生产超高性能金属合金，不依赖于熔化原材料。他们的固态冶金技术使得下一代合金的开发和制造变得更简单，产品开发速度更快，强度是传统金属的两倍。公司旨在为航空航天、自行车、汽车等行业提供更可靠、性能更高的金属材料。&lt;/p&gt;</description>
        </item>
        <item>
        <title>AI药物发现再进化：分子之心、斯坦福开发SurfFlow系统，破解治疗性肽设计表面互补难题</title>
        <link>https://caxlee.github.io/p/ai%E8%8D%AF%E7%89%A9%E5%8F%91%E7%8E%B0%E5%86%8D%E8%BF%9B%E5%8C%96%E5%88%86%E5%AD%90%E4%B9%8B%E5%BF%83%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%BC%80%E5%8F%91surfflow%E7%B3%BB%E7%BB%9F%E7%A0%B4%E8%A7%A3%E6%B2%BB%E7%96%97%E6%80%A7%E8%82%BD%E8%AE%BE%E8%AE%A1%E8%A1%A8%E9%9D%A2%E4%BA%92%E8%A1%A5%E9%9A%BE%E9%A2%98/</link>
        <pubDate>Mon, 14 Jul 2025 21:13:58 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/ai%E8%8D%AF%E7%89%A9%E5%8F%91%E7%8E%B0%E5%86%8D%E8%BF%9B%E5%8C%96%E5%88%86%E5%AD%90%E4%B9%8B%E5%BF%83%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%BC%80%E5%8F%91surfflow%E7%B3%BB%E7%BB%9F%E7%A0%B4%E8%A7%A3%E6%B2%BB%E7%96%97%E6%80%A7%E8%82%BD%E8%AE%BE%E8%AE%A1%E8%A1%A8%E9%9D%A2%E4%BA%92%E8%A1%A5%E9%9A%BE%E9%A2%98/</guid>
        <description>&lt;p&gt;近年来，科学家在设计靶向难成药位点的治疗性肽方面取得进展，但忽略了蛋白质相互作用中分子表面的重要影响。为弥补这一差距，研究团队提出了一种基于表面的全设计肽生成算法SurfFlow，采用多模态条件流匹配架构来提高肽结合的准确性。该算法在全面的基准测试中表现优异，展现了整合多种蛋白质模态的潜力。&lt;/p&gt;</description>
        </item>
        <item>
        <title>RL 圈的夏夜之约！12 人唠嗑局：当强化学习撞上大模型 Agent</title>
        <link>https://caxlee.github.io/p/rl-%E5%9C%88%E7%9A%84%E5%A4%8F%E5%A4%9C%E4%B9%8B%E7%BA%A612-%E4%BA%BA%E5%94%A0%E5%97%91%E5%B1%80%E5%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%92%9E%E4%B8%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B-agent/</link>
        <pubDate>Mon, 14 Jul 2025 21:13:58 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/rl-%E5%9C%88%E7%9A%84%E5%A4%8F%E5%A4%9C%E4%B9%8B%E7%BA%A612-%E4%BA%BA%E5%94%A0%E5%97%91%E5%B1%80%E5%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%92%9E%E4%B8%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B-agent/</guid>
        <description>&lt;p&gt;本文介绍了由机器之心主办、东浩兰生支持的「强化学习新范式探索之夜」活动，主题是从基础模型到 Agent 的进阶之路，邀请学术界和产业界的专家分享关于强化学习和大模型智能体的讨论。活动将围绕强化学习与大模型智能体的组合、训练推理策略选择以及智能体评估等议题展开，旨在打造一个小而精的交流平台。&lt;/p&gt;</description>
        </item>
        <item>
        <title>模拟3D分子编辑，北大高毅勤团队开发整合物理信息和偏好对齐的MolEdit，登Nature子刊</title>
        <link>https://caxlee.github.io/p/%E6%A8%A1%E6%8B%9F3d%E5%88%86%E5%AD%90%E7%BC%96%E8%BE%91%E5%8C%97%E5%A4%A7%E9%AB%98%E6%AF%85%E5%8B%A4%E5%9B%A2%E9%98%9F%E5%BC%80%E5%8F%91%E6%95%B4%E5%90%88%E7%89%A9%E7%90%86%E4%BF%A1%E6%81%AF%E5%92%8C%E5%81%8F%E5%A5%BD%E5%AF%B9%E9%BD%90%E7%9A%84moledit%E7%99%BBnature%E5%AD%90%E5%88%8A/</link>
        <pubDate>Mon, 14 Jul 2025 21:13:58 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E6%A8%A1%E6%8B%9F3d%E5%88%86%E5%AD%90%E7%BC%96%E8%BE%91%E5%8C%97%E5%A4%A7%E9%AB%98%E6%AF%85%E5%8B%A4%E5%9B%A2%E9%98%9F%E5%BC%80%E5%8F%91%E6%95%B4%E5%90%88%E7%89%A9%E7%90%86%E4%BF%A1%E6%81%AF%E5%92%8C%E5%81%8F%E5%A5%BD%E5%AF%B9%E9%BD%90%E7%9A%84moledit%E7%99%BBnature%E5%AD%90%E5%88%8A/</guid>
        <description>&lt;p&gt;北京大学团队提出了理论指导，用于弥合图像 GenAI 和分子 GenAI 之间的方法论差距，实现对 3D 分子生成基础模型的预训练。他们开发的多模态分子 GenAI——MolEdit 能够生成具有全面对称性的有效分子，平衡构型稳定性和构象多样性，支持复杂三维结构的生成。研究人员通过物理信息学习和数据驱动学习相结合，解决了分子 GenAI 的幻觉问题，使得 MolEdit 在药物设计等领域具有广泛应用前景。&lt;/p&gt;</description>
        </item>
        <item>
        <title>登《Cell》，中科院高彩霞等开发AiCE：一种AI蛋白质工程通用策略</title>
        <link>https://caxlee.github.io/p/%E7%99%BBcell%E4%B8%AD%E7%A7%91%E9%99%A2%E9%AB%98%E5%BD%A9%E9%9C%9E%E7%AD%89%E5%BC%80%E5%8F%91aice%E4%B8%80%E7%A7%8Dai%E8%9B%8B%E7%99%BD%E8%B4%A8%E5%B7%A5%E7%A8%8B%E9%80%9A%E7%94%A8%E7%AD%96%E7%95%A5/</link>
        <pubDate>Mon, 14 Jul 2025 21:13:58 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E7%99%BBcell%E4%B8%AD%E7%A7%91%E9%99%A2%E9%AB%98%E5%BD%A9%E9%9C%9E%E7%AD%89%E5%BC%80%E5%8F%91aice%E4%B8%80%E7%A7%8Dai%E8%9B%8B%E7%99%BD%E8%B4%A8%E5%B7%A5%E7%A8%8B%E9%80%9A%E7%94%A8%E7%AD%96%E7%95%A5/</guid>
        <description>&lt;p&gt;中国科学院团队开发的AiCE框架通过整合结构和进化约束到反向折叠模型中，实现了快速高效的蛋白质工程，无需专门训练。该框架在蛋白质工程任务中取得了显著成功，能够预测高适应性突变并优化蛋白质结构，展现出良好的应用前景。&lt;/p&gt;</description>
        </item>
        <item>
        <title>QS ranks MIT the world’s No. 1 university for 2025-26</title>
        <link>https://caxlee.github.io/p/qs-ranks-mit-the-worlds-no-1-university-for-2025-26/</link>
        <pubDate>Sun, 13 Jul 2025 13:55:19 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/qs-ranks-mit-the-worlds-no-1-university-for-2025-26/</guid>
        <description>&lt;p&gt;麻省理工学院再次荣获QS世界大学排名榜首，连续14年蝉联该荣誉。该排名基于学术声誉、雇主声誉、每位教职员工的引用次数、师生比例、国际教职员比例以及国际学生比例等因素。此外，MIT在11个学科领域中名列榜首，包括化学工程、计算机科学与信息系统、数据科学与人工智能等。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Supporting mission-driven space innovation, for Earth and beyond</title>
        <link>https://caxlee.github.io/p/supporting-mission-driven-space-innovation-for-earth-and-beyond/</link>
        <pubDate>Sat, 12 Jul 2025 23:34:59 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/supporting-mission-driven-space-innovation-for-earth-and-beyond/</guid>
        <description>&lt;p&gt;Aurelia Institute成立于MIT的校友和前研究科学家组成，致力于使太空技术和建筑对全人类都有益处。该机构通过微重力飞行等活动，培养下一代太空爱好者，同时致力于为低地球轨道的大规模基础设施项目提供技术支持。他们的工作包括自组装太空建筑技术TESSERAE以及设计人类规模的建筑和栖息地，旨在将太空技术和理念带回地球。&lt;/p&gt;</description>
        </item>
        <item>
        <title>告别Transformer！北大、北邮、华为开源纯卷积DiC：3x3卷积实现SOTA性能，比DiT快5倍！</title>
        <link>https://caxlee.github.io/p/%E5%91%8A%E5%88%ABtransformer%E5%8C%97%E5%A4%A7%E5%8C%97%E9%82%AE%E5%8D%8E%E4%B8%BA%E5%BC%80%E6%BA%90%E7%BA%AF%E5%8D%B7%E7%A7%AFdic3x3%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B0sota%E6%80%A7%E8%83%BD%E6%AF%94dit%E5%BF%AB5%E5%80%8D/</link>
        <pubDate>Sat, 12 Jul 2025 23:34:59 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E5%91%8A%E5%88%ABtransformer%E5%8C%97%E5%A4%A7%E5%8C%97%E9%82%AE%E5%8D%8E%E4%B8%BA%E5%BC%80%E6%BA%90%E7%BA%AF%E5%8D%B7%E7%A7%AFdic3x3%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B0sota%E6%80%A7%E8%83%BD%E6%AF%94dit%E5%BF%AB5%E5%80%8D/</guid>
        <description>&lt;p&gt;近期北大、北邮和华为联合研究提出了一种新的纯卷积扩散模型DiC，重新审视了深度学习中的基础模块3x3卷积，超越了Diffusion Transformer在性能和推理速度上，证明了简单的卷积网络在生成任务中的潜力。他们通过精心设计的U-Net Hourglass架构、条件注入和激活函数替换等方式，将平庸的卷积网络打造成性能卓越的模型。&lt;/p&gt;</description>
        </item>
        <item>
        <title>拍我AI（PixVerse）上线多关键帧生成功能 ，AI视频创作从“片段”迈向“故事性表达” </title>
        <link>https://caxlee.github.io/p/%E6%8B%8D%E6%88%91aipixverse%E4%B8%8A%E7%BA%BF%E5%A4%9A%E5%85%B3%E9%94%AE%E5%B8%A7%E7%94%9F%E6%88%90%E5%8A%9F%E8%83%BD-ai%E8%A7%86%E9%A2%91%E5%88%9B%E4%BD%9C%E4%BB%8E%E7%89%87%E6%AE%B5%E8%BF%88%E5%90%91%E6%95%85%E4%BA%8B%E6%80%A7%E8%A1%A8%E8%BE%BE/</link>
        <pubDate>Sat, 12 Jul 2025 23:34:59 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E6%8B%8D%E6%88%91aipixverse%E4%B8%8A%E7%BA%BF%E5%A4%9A%E5%85%B3%E9%94%AE%E5%B8%A7%E7%94%9F%E6%88%90%E5%8A%9F%E8%83%BD-ai%E8%A7%86%E9%A2%91%E5%88%9B%E4%BD%9C%E4%BB%8E%E7%89%87%E6%AE%B5%E8%BF%88%E5%90%91%E6%95%85%E4%BA%8B%E6%80%A7%E8%A1%A8%E8%BE%BE/</guid>
        <description>&lt;p&gt;拍我AI新增了多关键帧生成功能，用户可上传最多7张图片，在首尾帧模式下生成最长30秒的连贯视频，增强了创作者对AI视频叙事的掌控力。这一功能使AI视频创作更具完整叙事连贯性，能够实现角色动作、场景转换的自然衔接，智能切换不同景别与视角，显著提升叙事表现力，为高叙事需求场景提升创作效率。&lt;/p&gt;</description>
        </item>
        <item>
        <title>马斯克吹牛了吗？Grok 4第一波实测出炉：既能完虐o3，也菜到数不清6根手指</title>
        <link>https://caxlee.github.io/p/%E9%A9%AC%E6%96%AF%E5%85%8B%E5%90%B9%E7%89%9B%E4%BA%86%E5%90%97grok-4%E7%AC%AC%E4%B8%80%E6%B3%A2%E5%AE%9E%E6%B5%8B%E5%87%BA%E7%82%89%E6%97%A2%E8%83%BD%E5%AE%8C%E8%99%90o3%E4%B9%9F%E8%8F%9C%E5%88%B0%E6%95%B0%E4%B8%8D%E6%B8%856%E6%A0%B9%E6%89%8B%E6%8C%87/</link>
        <pubDate>Sat, 12 Jul 2025 23:34:59 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E9%A9%AC%E6%96%AF%E5%85%8B%E5%90%B9%E7%89%9B%E4%BA%86%E5%90%97grok-4%E7%AC%AC%E4%B8%80%E6%B3%A2%E5%AE%9E%E6%B5%8B%E5%87%BA%E7%82%89%E6%97%A2%E8%83%BD%E5%AE%8C%E8%99%90o3%E4%B9%9F%E8%8F%9C%E5%88%B0%E6%95%B0%E4%B8%8D%E6%B8%856%E6%A0%B9%E6%89%8B%E6%8C%87/</guid>
        <description>&lt;p&gt;马斯克亮相 Grok 4 发布会，宣称所有学科都达到博士后水平，吸引全球网友兴趣。比较 Grok 4 和 o3 在多个测试中表现，Grok 4 获得更多胜利。Grok 4 在教育领域应用潜力巨大，能够让抽象概念可视化，制作经典游戏和模拟。然而在实测中也出现翻车现象，引发一些讨论。&lt;/p&gt;</description>
        </item>
        <item>
        <title>8小时处理300万细胞数据，复旦&amp;上交研发双分支架构模型，登Nature子刊</title>
        <link>https://caxlee.github.io/p/8%E5%B0%8F%E6%97%B6%E5%A4%84%E7%90%86300%E4%B8%87%E7%BB%86%E8%83%9E%E6%95%B0%E6%8D%AE%E5%A4%8D%E6%97%A6%E4%B8%8A%E4%BA%A4%E7%A0%94%E5%8F%91%E5%8F%8C%E5%88%86%E6%94%AF%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%9E%8B%E7%99%BBnature%E5%AD%90%E5%88%8A/</link>
        <pubDate>Thu, 10 Jul 2025 22:06:08 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/8%E5%B0%8F%E6%97%B6%E5%A4%84%E7%90%86300%E4%B8%87%E7%BB%86%E8%83%9E%E6%95%B0%E6%8D%AE%E5%A4%8D%E6%97%A6%E4%B8%8A%E4%BA%A4%E7%A0%94%E5%8F%91%E5%8F%8C%E5%88%86%E6%94%AF%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%9E%8B%E7%99%BBnature%E5%AD%90%E5%88%8A/</guid>
        <description>&lt;p&gt;复旦大学与上海交通大学团队提出了 River 框架，利用双分支预测架构和事后归因策略，能够识别基因空间位置变化的关键信号。River 在识别差异空间表达模式基因方面表现优异，比传统方法更具优势。研究展示了 River 在不同数据集上的性能优势，以及在实际生物场景中的强大表现。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Collaborating with the force of nature</title>
        <link>https://caxlee.github.io/p/collaborating-with-the-force-of-nature/</link>
        <pubDate>Thu, 10 Jul 2025 22:06:08 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/collaborating-with-the-force-of-nature/</guid>
        <description>&lt;p&gt;麻省理工学院的教授们在冰岛部署了一系列轻便的钢结构，用于与火山熔岩互动并成功转移其流向，以保护人类居住区和重要基础设施。他们的研究得到了教授阿马尔·G·博斯研究基金的支持。通过设计不同形状和材料的结构，他们希望与火山熔岩合作，而非对抗它。这项研究的目标是为全球其他活火山地区开发关键基础设施。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Implantable device could save diabetes patients from dangerously low blood sugar</title>
        <link>https://caxlee.github.io/p/implantable-device-could-save-diabetes-patients-from-dangerously/</link>
        <pubDate>Thu, 10 Jul 2025 22:06:08 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/implantable-device-could-save-diabetes-patients-from-dangerously/</guid>
        <description>&lt;p&gt;麻省理工学院工程师设计了一种可植入的胰高血糖素释放装置，可在血糖水平过低时释放药物，帮助糖尿病患者应对低血糖危机。这种装置还可用于释放肾上腺素，应对心脏病发作和严重过敏反应。研究人员计划未来三年内开始临床试验。&lt;/p&gt;</description>
        </item>
        <item>
        <title>Meta为他豪掷2亿美元，上交校友庞若鸣，晒出在苹果的最新论文</title>
        <link>https://caxlee.github.io/p/meta%E4%B8%BA%E4%BB%96%E8%B1%AA%E6%8E%B72%E4%BA%BF%E7%BE%8E%E5%85%83%E4%B8%8A%E4%BA%A4%E6%A0%A1%E5%8F%8B%E5%BA%9E%E8%8B%A5%E9%B8%A3%E6%99%92%E5%87%BA%E5%9C%A8%E8%8B%B9%E6%9E%9C%E7%9A%84%E6%9C%80%E6%96%B0%E8%AE%BA%E6%96%87/</link>
        <pubDate>Thu, 10 Jul 2025 22:06:08 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/meta%E4%B8%BA%E4%BB%96%E8%B1%AA%E6%8E%B72%E4%BA%BF%E7%BE%8E%E5%85%83%E4%B8%8A%E4%BA%A4%E6%A0%A1%E5%8F%8B%E5%BA%9E%E8%8B%A5%E9%B8%A3%E6%99%92%E5%87%BA%E5%9C%A8%E8%8B%B9%E6%9E%9C%E7%9A%84%E6%9C%80%E6%96%B0%E8%AE%BA%E6%96%87/</guid>
        <description>&lt;p&gt;庞若鸣即将加入 Meta 新成立的超级智能团队，但在苹果负责的最后一项研究中，他介绍了基于多模态大规模模型训练的 AXLearn 系统，具备高度模块化和对异构硬件的支持。该系统通过严格封装实现模块化，成功集成了 RoPE 和 MoE 功能，保持恒定的代码复杂性，并在异构硬件上展现出优异的性能。&lt;/p&gt;</description>
        </item>
        <item>
        <title>人类增强子突变敏感性图谱首次绘制：AI 与体内实验揭示发育调控密码</title>
        <link>https://caxlee.github.io/p/%E4%BA%BA%E7%B1%BB%E5%A2%9E%E5%BC%BA%E5%AD%90%E7%AA%81%E5%8F%98%E6%95%8F%E6%84%9F%E6%80%A7%E5%9B%BE%E8%B0%B1%E9%A6%96%E6%AC%A1%E7%BB%98%E5%88%B6ai-%E4%B8%8E%E4%BD%93%E5%86%85%E5%AE%9E%E9%AA%8C%E6%8F%AD%E7%A4%BA%E5%8F%91%E8%82%B2%E8%B0%83%E6%8E%A7%E5%AF%86%E7%A0%81/</link>
        <pubDate>Thu, 10 Jul 2025 22:06:08 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E4%BA%BA%E7%B1%BB%E5%A2%9E%E5%BC%BA%E5%AD%90%E7%AA%81%E5%8F%98%E6%95%8F%E6%84%9F%E6%80%A7%E5%9B%BE%E8%B0%B1%E9%A6%96%E6%AC%A1%E7%BB%98%E5%88%B6ai-%E4%B8%8E%E4%BD%93%E5%86%85%E5%AE%9E%E9%AA%8C%E6%8F%AD%E7%A4%BA%E5%8F%91%E8%82%B2%E8%B0%83%E6%8E%A7%E5%AF%86%E7%A0%81/</guid>
        <description>&lt;p&gt;ENCODE计划揭示人类基因组中大部分序列为非编码区，长期调控功能成谜。研究团队通过转基因小鼠模型和机器学习系统性绘制了人类发育增强子的突变敏感性图谱，揭示了增强子在动物发育中的重要作用。研究结果有助于解释人类非编码变异和进化变化，为设计合成增强子以满足生物技术和治疗需求提供基础。&lt;/p&gt;</description>
        </item>
        <item>
        <title>基于工作记忆的认知测试显示LLM的检索局限：100%混淆无效信息与正确答案</title>
        <link>https://caxlee.github.io/p/%E5%9F%BA%E4%BA%8E%E5%B7%A5%E4%BD%9C%E8%AE%B0%E5%BF%86%E7%9A%84%E8%AE%A4%E7%9F%A5%E6%B5%8B%E8%AF%95%E6%98%BE%E7%A4%BAllm%E7%9A%84%E6%A3%80%E7%B4%A2%E5%B1%80%E9%99%90100%E6%B7%B7%E6%B7%86%E6%97%A0%E6%95%88%E4%BF%A1%E6%81%AF%E4%B8%8E%E6%AD%A3%E7%A1%AE%E7%AD%94%E6%A1%88/</link>
        <pubDate>Thu, 10 Jul 2025 22:06:08 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E5%9F%BA%E4%BA%8E%E5%B7%A5%E4%BD%9C%E8%AE%B0%E5%BF%86%E7%9A%84%E8%AE%A4%E7%9F%A5%E6%B5%8B%E8%AF%95%E6%98%BE%E7%A4%BAllm%E7%9A%84%E6%A3%80%E7%B4%A2%E5%B1%80%E9%99%90100%E6%B7%B7%E6%B7%86%E6%97%A0%E6%95%88%E4%BF%A1%E6%81%AF%E4%B8%8E%E6%AD%A3%E7%A1%AE%E7%AD%94%E6%A1%88/</guid>
        <description>&lt;p&gt;本文发现了一个影响所有大型语言模型的信息检索问题，即无法稳定地提取动态数据中的最新信息，对全局记忆和长推理任务造成损害。研究表明，所有主流语言模型在处理动态数据时会出现明显的错误，并呈现出一致的对数线性下降趋势。作者提出这一问题可能源于模型的基础架构或依赖的注意力机制。实验结果暗示，模型的抗干扰容量不足，需要在模型架构设计或训练方法上进行创新性调整。&lt;/p&gt;</description>
        </item>
        <item>
        <title>我们用飞书开了个选题会，一下进入现代化办公，编辑部直呼：真香</title>
        <link>https://caxlee.github.io/p/%E6%88%91%E4%BB%AC%E7%94%A8%E9%A3%9E%E4%B9%A6%E5%BC%80%E4%BA%86%E4%B8%AA%E9%80%89%E9%A2%98%E4%BC%9A%E4%B8%80%E4%B8%8B%E8%BF%9B%E5%85%A5%E7%8E%B0%E4%BB%A3%E5%8C%96%E5%8A%9E%E5%85%AC%E7%BC%96%E8%BE%91%E9%83%A8%E7%9B%B4%E5%91%BC%E7%9C%9F%E9%A6%99/</link>
        <pubDate>Thu, 10 Jul 2025 22:06:08 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E6%88%91%E4%BB%AC%E7%94%A8%E9%A3%9E%E4%B9%A6%E5%BC%80%E4%BA%86%E4%B8%AA%E9%80%89%E9%A2%98%E4%BC%9A%E4%B8%80%E4%B8%8B%E8%BF%9B%E5%85%A5%E7%8E%B0%E4%BB%A3%E5%8C%96%E5%8A%9E%E5%85%AC%E7%BC%96%E8%BE%91%E9%83%A8%E7%9B%B4%E5%91%BC%E7%9C%9F%E9%A6%99/</guid>
        <description>&lt;p&gt;飞书在2025飞书未来无限大会上发布了多项新产品和升级，包括知识问答、AI会议、飞书Aily、飞书妙搭等。其中，飞书知识问答达到了M3标准，能够快速检索和整合信息；飞书会议则达到了M4标准，支持声纹识别和实时总结。另外，多维表格也迎来重大升级，包括性能提升和AI工具全家桶的发布。&lt;/p&gt;</description>
        </item>
        <item>
        <title>联合国点赞爱诗科技，PixVerse入选AI for Good优秀案例</title>
        <link>https://caxlee.github.io/p/%E8%81%94%E5%90%88%E5%9B%BD%E7%82%B9%E8%B5%9E%E7%88%B1%E8%AF%97%E7%A7%91%E6%8A%80pixverse%E5%85%A5%E9%80%89ai-for-good%E4%BC%98%E7%A7%80%E6%A1%88%E4%BE%8B/</link>
        <pubDate>Thu, 10 Jul 2025 22:06:08 +0800</pubDate>
        
        <guid>https://caxlee.github.io/p/%E8%81%94%E5%90%88%E5%9B%BD%E7%82%B9%E8%B5%9E%E7%88%B1%E8%AF%97%E7%A7%91%E6%8A%80pixverse%E5%85%A5%E9%80%89ai-for-good%E4%BC%98%E7%A7%80%E6%A1%88%E4%BE%8B/</guid>
        <description>&lt;p&gt;爱诗科技旗下生成式AI视频平台PixVerse在联合国举办的人工智能向善全球峰会上分享了其创意和数字包容成果，旨在推动“AI视频向善”的理念。通过创新的一键生成技术，PixVerse赋予全球数亿用户视频创作能力，重构创作经济生态，实现了视频创作的普惠。PixVerse的包容性潜力得到了实际印证，各国用户通过平台创作出惊艳作品，彰显了AI视频技术的巨大潜力和影响力。&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>
